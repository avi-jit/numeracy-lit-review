"id","url","score","title","summary","venue","year","authors","citationCount","referenceCount","influentialCitationCount"
"9160673f89ecb326db8c64f8d09ab30f35a74e9d","https://www.semanticscholar.org/paper/9160673f89ecb326db8c64f8d09ab30f35a74e9d",3,"Arithmetic with Language Models: from Memorization to Computation","The findings support the hypothesis that the language model works as an Encoding-Regression-Decoding machine where the computation takes place in the value space once the input token representation is mapped to an appropriate internal representation.","arXiv.org",2023,"D. Maltoni,M. Ferrara",0,27,0
"dd69049674f41d4ef5314b8f95bacfe59de31376","https://www.semanticscholar.org/paper/dd69049674f41d4ef5314b8f95bacfe59de31376",2,"Conditions for Length Generalization in Learning Reasoning Skills","This work identifies and proves conditions that decide whether the length generalization problem can be solved or not for a reasoning task in a particular representation.","arXiv.org",2023,"Changnan Xiao,Bing Liu",2,68,0
"49c45d2a2773c537804c38d69cde67e00fbad6fe","https://www.semanticscholar.org/paper/49c45d2a2773c537804c38d69cde67e00fbad6fe",2,"Tokenization counts: the impact of tokenization on arithmetic in frontier LLMs","This work performs the first study of how number tokenization choices lead to differences in model performance on arithmetic tasks, accompanied by a thorough analysis of error patterns.","",2024,"Aaditya K. Singh,DJ Strouse",0,40,0
"817e52b815560f95171d8fa60f78dd965e885a65","https://www.semanticscholar.org/paper/817e52b815560f95171d8fa60f78dd965e885a65",2,"How well do Large Language Models perform in Arithmetic tasks?","This work proposes an arithmetic dataset MATH 401 to test the latest large language models including GPT-4, ChatG PT, InstrctGPT, Galactica, and LLaMA with various arithmetic expressions and provides a detailed analysis of the ability of largelanguage models.","arXiv.org",2023,"Zheng Yuan,Hongyi Yuan,Chuanqi Tan,Wei Wang,Songfang Huang",52,35,3
"8c7846c9805834dbe2fb0c8f48253b8d65b79d6a","https://www.semanticscholar.org/paper/8c7846c9805834dbe2fb0c8f48253b8d65b79d6a",2,"Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks","Goat, a fine-tuned LLaMA model that significantly outperforms GPT-4 on a range of arithmetic tasks, is introduced and an approach that classifies tasks based on their learnability, and subsequently decomposes unlearnable tasks into a series of learnable tasks by leveraging basic arithmetic principles is proposed.","arXiv.org",2023,"Tiedong Liu,K. H. Low",34,40,3
"ee7b871213e1deafadea4b7752467b5c5ab1b9fb","https://www.semanticscholar.org/paper/ee7b871213e1deafadea4b7752467b5c5ab1b9fb",2,"GPT Can Solve Mathematical Problems Without a Calculator","The MathGLM, fine-tuned from GLM-10B on a dataset with additional multi-step arithmetic operations and math problems described in text, achieves similar performance to GPT-4 on a 5,000-samples Chinese math problem test set.","arXiv.org",2023,"Z. Yang,Ming Ding,Qingsong Lv,Zhihuan Jiang,Zehai He,Yuyi Guo,Jinfeng Bai,Jie Tang",16,45,0
"b1fe7bdcfef4e12febe7e8bed8826e66689d60ed","https://www.semanticscholar.org/paper/b1fe7bdcfef4e12febe7e8bed8826e66689d60ed",2,"Auto-Regressive Next-Token Predictors are Universal Learners","This work presents a theoretical framework for studying auto-regressive next-token predictors, and introduces a new complexity measure -- length complexity -- which measures the number of intermediate tokens in a CoT sequence required to approximate some target function, and examines the interplay between length complexity and other notions of complexity.","arXiv.org",2023,"Eran Malach",5,48,0
"5ee871537ae51e7e2e93d2a70fff5d100649a655","https://www.semanticscholar.org/paper/5ee871537ae51e7e2e93d2a70fff5d100649a655",2,"Mathematical Language Models: A Survey","A comprehensive survey of mathematical LMs is conducted, systematically categorizing pivotal research endeavors from two distinct perspectives: tasks and methodologies, revealing a large number of proposed mathematical LLMs.","arXiv.org",2023,"Wentao Liu,Hanglei Hu,Jie Zhou,Yuyang Ding,Junsong Li,Jiayi Zeng,Mengliang He,Qin Chen,Bo Jiang,Aimin Zhou,Liang He",0,220,0
"4372100e5f676b0a2db93a97b6b1e45ae593b75e","https://www.semanticscholar.org/paper/4372100e5f676b0a2db93a97b6b1e45ae593b75e",2,"Understanding the Effect of Noise in LLM Training Data with Algorithmic Chains of Thought","This work develops the Traced Integer framework to generate highly customizable noised execution traces for any arithmetic function on lists of integers and evaluates the test performance of pretrained models both prompted and fine-tuned on noised datasets with varying levels of dataset contamination and intensity.","arXiv.org",2024,"Alex Havrilla,Maia Iyer",0,43,0
"3dc9eb80b806f2db14a45216a7fd840153f45a07","https://www.semanticscholar.org/paper/3dc9eb80b806f2db14a45216a7fd840153f45a07",1,"Don’t be Blind to Questions: Question-Oriented Math Word Problem Solving","This approach features an entity-aware encoder that enhances the connection between MWP context and question via entities in established dependency graphs, aiming at obtaining better problem representations and a question-guided decoder is trained using a contrastive learning strategy to enhance the question representations.","International Joint Conference on Natural Language Processing",2023,"Zhenwen Liang,Jipeng Zhang,Xiangliang Zhang",0,49,0
"0b47c8eae44c8c3c5f474d1b9869ba90a5199eae","https://www.semanticscholar.org/paper/0b47c8eae44c8c3c5f474d1b9869ba90a5199eae",1,"Math Word Problem Solving by Generating Linguistic Variants of Problem Statements","This paper proposes a framework for MWP solvers based on the generation of linguistic variants of the problem text and shows that training on linguistic variant of problem statements and voting on candidate predictions improve the mathematical reasoning and robustness of the model.","Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop)",2023,"Syed Rifat Raiyan,Md. Nafis Faiyaz,S. Kabir,Mohsinul Kabir,H. Mahmud,Md. Kamrul Hasan",1,111,0
"c1c93b4916aa5b8ce1d99a9e59c700e3d13ada36","https://www.semanticscholar.org/paper/c1c93b4916aa5b8ce1d99a9e59c700e3d13ada36",1,"MinT: Boosting Generalization in Mathematical Reasoning via Multi-View Fine-Tuning","This work introduces a multi-view fine-tuning method that efficiently exploits existing mathematical problem datasets with diverse annotation styles, and uniquely considers the various annotation formats as different""views"" and leverages them in training the model.","arXiv.org",2023,"Zhenwen Liang,Dian Yu,Xiaoman Pan,Wenlin Yao,Qingkai Zeng,Xiangliang Zhang,Dong Yu",4,45,0
"e1414fc1e1a6752524a1807a29ee406e8d808849","https://www.semanticscholar.org/paper/e1414fc1e1a6752524a1807a29ee406e8d808849",1,"Auto-Instruct: Automatic Instruction Generation and Ranking for Black-Box Language Models","This paper introduces Auto-Instruct, a novel method to automatically improve the quality of instructions provided to LLMs, and leverages the inherent generative ability of LLMs to produce diverse candidate instructions for a given task, and then ranks them using a scoring model trained on a variety of 575 existing NLP tasks.","Conference on Empirical Methods in Natural Language Processing",2023,"Zhihan Zhang,Shuo Wang,W. Yu,Yichong Xu,Dan Iter,Qingkai Zeng,Yang Liu,Chenguang Zhu,Meng Jiang",5,38,0
"98b607e7cb84e1a5c87c8a49562ae35435e6722d","https://www.semanticscholar.org/paper/98b607e7cb84e1a5c87c8a49562ae35435e6722d",1,"Learning From Mistakes Makes LLM Better Reasoner","Experiments show that \textsc{LeMa} consistently improves CoT-alone fine-tuning and sheds light on the non-homogeneous effectiveness between CoT data and correction data, and the contribution from different correction information.","arXiv.org",2023,"Shengnan An,Zexiong Ma,Zeqi Lin,Nanning Zheng,Jian-Guang Lou,Weizhu Chen",9,56,3
"631b5baa2c34f7095ccdd8761086b49148071d78","https://www.semanticscholar.org/paper/631b5baa2c34f7095ccdd8761086b49148071d78",1,"Knowledge Distillation of LLM for Automatic Scoring of Science Education Assessments","A method for knowledge distillation of fine-tuned Large Language Models into smaller, more efficient, and accurate neural networks that has potential to make advanced AI technologies accessible in typical educational settings, particularly for automatic scoring.","",2023,"Ehsan Latif,Luyang Fang,Ping Ma,Xiaoming Zhai",0,39,0
"1a6bd4f70bceb26ddb722ce98c0eae2a64147048","https://www.semanticscholar.org/paper/1a6bd4f70bceb26ddb722ce98c0eae2a64147048",1,"Knowledge-Based and Generative-AI-Driven Pedagogical Conversational Agents: A Comparative Study of Grice's Cooperative Principles and Trust","This paper investigates how a very limited amount of domain-specific data can be used to build knowledge-based and generative educational chatbots and finds that knowledge-based chatbots allow full control over the system’s response but lack the verbosity and flexibility of GLMs.","Big Data and Cognitive Computing",2023,"Matthias Wölfel,Mehrnoush Barani Shirzad,Andreas Reich,Katharina Anderer",0,71,0
"04cc5744fe8b436fb0f8b2763ed8ac7e4a60f7d1","https://www.semanticscholar.org/paper/04cc5744fe8b436fb0f8b2763ed8ac7e4a60f7d1",1,"Combining GPT and Colab as learning tools for students to explore the numerical solutions of difference equations","","Eurasia Journal of Mathematics, Science and Technology Education",2024,"Supot Seebut,Patcharee Wongsason,Dojin Kim",0,48,0
"8f070e301979732e0dd73f6aa6170309cf73aa7d","https://www.semanticscholar.org/paper/8f070e301979732e0dd73f6aa6170309cf73aa7d",1,"Large Language Model based Multi-Agents: A Survey of Progress and Challenges","This survey is presented to offer an in-depth discussion on the essential aspects of multi-agent systems based on LLMs, as well as the challenges.","arXiv.org",2024,"Taicheng Guo,Xiuying Chen,Yaqi Wang,Ruidi Chang,Shichao Pei,N. Chawla,Olaf Wiest,Xiangliang Zhang",5,77,0
"d43587743abd006be30756b67efd87f61671412b","https://www.semanticscholar.org/paper/d43587743abd006be30756b67efd87f61671412b",1,"Tartare: Automatic Generation of C Pointer Statements and Feedback","The techniques implemented in Tartare are described, relying on a pattern template-based approach, and it is believed the approach for Tartare can be transposed for automatic exercises generation in various other fields.","IFAC Symposium on Advances in Control Education",2024,"Géraldine Brieven,Valentin Baum,Benoit Donnet",0,49,0
"42445823fb0156afddc8c72eaa5ee81dded5b965","https://www.semanticscholar.org/paper/42445823fb0156afddc8c72eaa5ee81dded5b965",1,"Large Language Models for Mathematical Reasoning: Progresses and Challenges","This survey stands as one of the first extensive examinations of the landscape of LLM-oriented techniques in the realm of mathematics, providing a holistic perspective on the current state, accomplishments, and future challenges in this rapidly evolving field.","arXiv.org",2024,"Janice Ahn,Rishu Verma,Renze Lou,Di Liu,Rui Zhang,Wenpeng Yin",4,92,0
"7f4bdef8c9d660af6b18a55de0699e5e65ce3b54","https://www.semanticscholar.org/paper/7f4bdef8c9d660af6b18a55de0699e5e65ce3b54",1,"Plan-Grounded Large Language Models for Dual Goal Conversational Settings","A novel LLM is proposed that grounds the dialogue on a procedural plan, can take the dialogue initiative, and enforces guardrails on the system's behavior, while also improving the LLM's responses to unexpected user behavior.","arXiv.org",2024,"Diogo Glória-Silva,Rafael Ferreira,Diogo Tavares,David Semedo,João Magalhães",1,43,0
"edc5b4b2b89718b42dc90192960084166b7987d8","https://www.semanticscholar.org/paper/edc5b4b2b89718b42dc90192960084166b7987d8",1,"Multi-Intent Attribute-Aware Text Matching in Searching","This work proposes a multi-intent attribute-aware matching model (MIM), which consists of three main components: attribute-aware encoder, multi-intent modeling, and intent-aware matching, which consists of three main components: attribute-aware encoder, multi-intent modeling, and intent-aware matching.","arXiv.org",2024,"Mingzhe Li,Xiuying Chen,Jing Xiang,Qishen Zhang,Changsheng Ma,Chenchen Dai,Jinxiong Chang,Zhongyi Liu,Guannan Zhang",0,41,0
"f5df0667365764a970fc6abfa0a68b7d1d0ae413","https://www.semanticscholar.org/paper/f5df0667365764a970fc6abfa0a68b7d1d0ae413",1,"Patchscopes: A Unifying Framework for Inspecting Hidden Representations of Language Models","It is shown that prior interpretability methods based on projecting representations into the vocabulary space and intervening on the LLM computation can be viewed as instances of this framework, and several of their shortcomings such as failure in inspecting early layers or lack of expressivity can be mitigated by Patchscopes.","arXiv.org",2024,"Asma Ghandeharioun,Avi Caciularu,Adam Pearce,Lucas Dixon,Mor Geva",6,64,1
"a14e999e8826f98cfd1cac9dd7baa4d0b61f7266","https://www.semanticscholar.org/paper/a14e999e8826f98cfd1cac9dd7baa4d0b61f7266",1,"Increasing Trust in Language Models through the Reuse of Verified Circuits","This paper fully verify a model for n-digit integer addition and discusses how inserting verified task modules into LMs can leverage model reuse to improve verifiability and trustworthiness of language models built using them.","arXiv.org",2024,"Philip Quirke,Clement Neo,Fazl Barez",0,17,0
"a05148b077418259989511ed8031ce05689a16aa","https://www.semanticscholar.org/paper/a05148b077418259989511ed8031ce05689a16aa",1,"AtP*: An efficient and scalable method for localizing LLM behaviour to components","This work investigates Attribution Patching (AtP), a fast gradient-based approximation to Activation Patching and finds two classes of failure modes of AtP which lead to significant false negatives, and proposes a variant of AtP called AtP*, with two changes to address these failure modes while retaining scalability.","",2024,"J'anos Kram'ar,Tom Lieberum,Rohin Shah,Neel Nanda",0,48,0
"b16d916ce411be0b1c7b6139317c652927984f46","https://www.semanticscholar.org/paper/b16d916ce411be0b1c7b6139317c652927984f46",1,"Tokenization on the Number Line is All You Need","This work proposes vocabulary 018 level changes in the decoding stage and studies its behavior and finds that changes at the 032 tokenization level achieve near state-of-the-art results while requiring minimal resources com-034 pared to other number representation schemes.","",2021,"",0,14,0
"b59947541d2ac4211c4b17554b2e16c260299bed","https://www.semanticscholar.org/paper/b59947541d2ac4211c4b17554b2e16c260299bed",1,"Have You Seen That Number? Investigating Extrapolation in Question Answering Models","This work rigorously tests state-of-the-art models on DROP, a numerical MRC dataset, and proposes the E-digit number form that alleviates the lack of extrapolation in models and reveals the need to treat numbers differently from regular words in the text.","Conference on Empirical Methods in Natural Language Processing",2021,"Jeonghwan Kim,Giwon Hong,Kyung-min Kim,Junmo Kang,Sung-Hyon Myaeng",15,20,1
"e39dfab0477ae28dbb18d49beb9cd4c7ea30486c","https://www.semanticscholar.org/paper/e39dfab0477ae28dbb18d49beb9cd4c7ea30486c",1,"On the Abilities of Mathematical Extrapolation with Implicit Models","This paper compares the robustness of implicitly-defined and classical deep learning models on a series of mathematical extrapolation tasks, where the models are tested with out-of-distribution samples during inference time.","",2022,"H. Larochelle",1,21,0
"5df55d94ab5026ff84ec01871592108fbadbddbe","https://www.semanticscholar.org/paper/5df55d94ab5026ff84ec01871592108fbadbddbe",1,"Measurement Extraction with Natural Language Processing: A Review","In this review, an overview of prior work on measurement extraction is presented and different approaches to measurement extraction are described and the challenges posed by this task are outlined.","Conference on Empirical Methods in Natural Language Processing",2022,"Jan Göpfert,Patrick Kuckertz,J. Weinand,Leander Kotzur,D. Stolten",3,175,0
"f8a36a6c10b4f598f7a936f09c58de31c9e10bcd","https://www.semanticscholar.org/paper/f8a36a6c10b4f598f7a936f09c58de31c9e10bcd",1,"Controlling Neural Network Smoothness for Algorithmic Neural Reasoning","Investigation of the underlying hypothesis in the most simple conceivable scenario – the addition of real numbers finds that two layer neural networks fail to learn the structure of this task and that growing the network’s width leads to a complex division of input space.","",2022,"",0,25,0
"346accd49d1359aa3985c7b298bc2057ae642271","https://www.semanticscholar.org/paper/346accd49d1359aa3985c7b298bc2057ae642271",1,"One Clinician Is All You Need–Cardiac Magnetic Resonance Imaging Measurement Extraction: Deep Learning Algorithm Development","This study demonstrated that a domain-agnostic pretrained transformer model is able to effectively extract quantitative clinical measurements from diagnostic reports with a relatively small number of gold-standard annotations.","",2022,"Pulkit Singh,Julian S. Haimovich,C. Reeder,S. Khurshid,S. Emily,Lau,Jonathan W Cunningham,A. Philippakis,C. D. Anderson,J. Ho,S. Lubitz,P. Batra",0,37,0
"c27f3904490b8e5f9f39fe2b36722090c189e916","https://www.semanticscholar.org/paper/c27f3904490b8e5f9f39fe2b36722090c189e916",1,"Applying Structural and Dense Semantic Matching for the ARQMath Lab 2022, CLEF","This work describes the participation of the team in the ARQMath 2022 Lab, where two highly complementary methods for effective math answer and formula retrieval are applied, using a lexical sparse retriever and a fine-tuned bi-encoder dense retriever to capture contextual similarity and semantic matching.","Conference and Labs of the Evaluation Forum",2022,"Wei Zhong,Yuqing Xie,Jimmy J. Lin",5,68,0
"58d5e4cbb5f3a944bae0bcc2bff93f06696f8196","https://www.semanticscholar.org/paper/58d5e4cbb5f3a944bae0bcc2bff93f06696f8196",1,"JRIRD at the NTCIR-16 FinNum-3 Task: Investigating the Effect of Numerical Representations in Manager’s Claim Detection","The jointlearning withnumerical categories improved the performance of some pre-trained models and numeral format settings.","",2022,"Shunsuke Onuma,Kazuma Kadowaki",3,16,1
"6c84fc8c5ec823342f34a020f8b92b7064e96ca2","https://www.semanticscholar.org/paper/6c84fc8c5ec823342f34a020f8b92b7064e96ca2",1,"Towards Efficient and Robust Out-of-Distribution Deep Learning with Implicit Models","This paper shows how to decrease implicit model training time by harnessing the state-driven implicit modeling framework to safely eliminate features while maintaining model accuracy.","",2023,"Ashwin Ganesh",0,49,0
"1d6ca8d8401e14bbb764d35ba13a9505af0dcc2f","https://www.semanticscholar.org/paper/1d6ca8d8401e14bbb764d35ba13a9505af0dcc2f",1,"Controlling Neural Network Smoothness for Neural Algorithmic Reasoning","A tight linkage between the scaling of a network weights’ standard deviation and its effective length scale on a sinusoidal regression problem is demonstrated, suggesting simple modifications to control the length scale of the function learned by a neural network and, thus, its smoothness.","Trans. Mach. Learn. Res.",2023,"David A. Klindt",1,75,0
"3693683c4e0405819fae7115ad680f769eb83534","https://www.semanticscholar.org/paper/3693683c4e0405819fae7115ad680f769eb83534",1,"Neural Comprehension: Language Models with Compiled Neural Networks","The method, which call ""Neural Comprehension"", helps language models achieve absolute accuracy in symbolic operations, thereby enhancing their ability for rule reasoning, symbolic reasoning, and arithmetic reasoning.","arXiv.org",2023,"Yixuan Weng,Minjun Zhu,Fei Xia,Bin Li,Shizhu He,Kang Liu,Jun Zhao",4,66,0
"28a5a53dafacebad8a7c47773079caeffb9a5baa","https://www.semanticscholar.org/paper/28a5a53dafacebad8a7c47773079caeffb9a5baa",1,"Representing Numbers in NLP: a Survey and a Vision","This work synthesizes best practices for representing numbers in text and articulate a vision for holistic numeracy in NLP, comprised of design trade-offs and a unified evaluation.","North American Chapter of the Association for Computational Linguistics",2021,"Avijit Thawani,J. Pujara,Pedro A. Szekely,Filip Ilievski",80,70,4
"a35d5aeba08cccdc5cdf26bc094ccd71d06bdc99","https://www.semanticscholar.org/paper/a35d5aeba08cccdc5cdf26bc094ccd71d06bdc99",1,"Exploring Generalization Ability of Pretrained Language Models on Arithmetic and Logical Reasoning","This research finds that the PLMs can easily generalize when the distribution is the same, however, it is still difficult for them to generalize out of the distribution.","Natural Language Processing and Chinese Computing",2021,"Cunxiang Wang,Boyuan Zheng,Y. Niu,Yue Zhang",14,36,0
"9ca329408813d209b1dcb36936f7f9cba82506bd","https://www.semanticscholar.org/paper/9ca329408813d209b1dcb36936f7f9cba82506bd",1,"Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation","This work shows that extrapolation can be enabled by simply changing the position representation method, though it finds that current methods do not allow for efficient extrapolation, and introduces a simpler and more efficient position method, Attention with Linear Biases (ALiBi).","International Conference on Learning Representations",2021,"Ofir Press,Noah A. Smith,M. Lewis",317,48,51
"0f2199296f01694ee46b6059879260fb80a84fa6","https://www.semanticscholar.org/paper/0f2199296f01694ee46b6059879260fb80a84fa6",1,"Teaching Autoregressive Language Models Complex Tasks By Demonstration","The results suggest that fine-tuning autoregressive language models on small sets of well-crafted demonstrations may be a useful paradigm for enabling individuals without training in machine learning to coax such models to perform some kinds of complex multi-step tasks.","arXiv.org",2021,"Gabriel Recchia",18,47,1
"37588705a2af7d5b24d901dd33ade1ff293aabdd","https://www.semanticscholar.org/paper/37588705a2af7d5b24d901dd33ade1ff293aabdd",1,"Investigating Numeracy Learning Ability of a Text-to-Text Transfer Model","This work investigates the ability of text-to-text transfer learning model (T5), which has outperformed its predecessors in the conventional NLP tasks, to learn numeracy, to struggle considerably in the extrapolation setting across all four tasks.","Conference on Empirical Methods in Natural Language Processing",2021,"Kuntal Pal,Chitta Baral",15,18,1
"aead4418733b998792deb9cbf198a834449e00d2","https://www.semanticscholar.org/paper/aead4418733b998792deb9cbf198a834449e00d2",1,"Symbolic Brittleness in Sequence Models: on Systematic Generalization in Symbolic Mathematics","A methodology for evaluating generalization that takes advantage of the problem domain's structure and access to a verifier is developed, and the problem of symbolic mathematical integration is considered, as it requires generalizing systematically beyond the training set.","AAAI Conference on Artificial Intelligence",2021,"S. Welleck,Peter West,Jize Cao,Yejin Choi",18,35,1
"b8b813111c411ae61881ab9cd25707d9de6444ec","https://www.semanticscholar.org/paper/b8b813111c411ae61881ab9cd25707d9de6444ec",1,"Compositional Attention: Disentangling Search and Retrieval","This work proposes a novel attention mechanism, called Compositional Attention, that replaces the standard head structure, and demonstrates that it outperforms standard multi-head attention on a variety of tasks, including some out-of-distribution settings.","arXiv.org",2021,"Sarthak Mittal,S. Raparthy,I. Rish,Yoshua Bengio,Guillaume Lajoie",11,52,1
"45ece6f3b0a319dba60c20b3013b5161dd49c58b","https://www.semanticscholar.org/paper/45ece6f3b0a319dba60c20b3013b5161dd49c58b",1,"Linear algebra with transformers","Nine problems of linear algebra are studied, from basic matrix operations to eigenvalue decomposition and inversion, and four encoding schemes to represent real numbers are introduced.","Trans. Mach. Learn. Res.",2021,"Franccois Charton",33,68,2
"edd80013e8b9fcba9231cf99884f32e5236ff329","https://www.semanticscholar.org/paper/edd80013e8b9fcba9231cf99884f32e5236ff329",1,"AA-TransUNet: Attention Augmented TransUNet For Nowcasting Tasks","A novel data-driven predictive model based on TransUNet for precipitation nowcasting task and shows that the proposed model outperforms other examined models on both tested datasets.","IEEE International Joint Conference on Neural Network",2022,"Yimin Yang,S. Mehrkanoon",22,36,3
"7a25155364476839b6d1fc0653cd8611327ab9ba","https://www.semanticscholar.org/paper/7a25155364476839b6d1fc0653cd8611327ab9ba",1,"mGPT: Few-Shot Learners Go Multilingual",,"Transactions of the Association for Computational Linguistics",2022,"Oleh Shliazhko,Alena Fenogenova,M. Tikhonova,V. Mikhailov,A. Kozlova,Tatiana Shavrina",71,116,7
"4f39ab027947f49fa9a9c919c2c09bbbe0bf7f80","https://www.semanticscholar.org/paper/4f39ab027947f49fa9a9c919c2c09bbbe0bf7f80",1,"Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence","A novel intermediate training task, names meaning-matching, designed to directly learn a meaning-text correspondence, is proposed that enables PLMs to learn lexical semantic information and is found to be a safe intermediate task that guarantees a similar or better performance of downstream tasks.","NAACL-HLT",2022,"Myeongjun Jang,Frank Mtumbuka,Thomas Lukasiewicz",6,53,1
"d2018d1b0f69ca6805aa18a22be95cab9b5c44c7","https://www.semanticscholar.org/paper/d2018d1b0f69ca6805aa18a22be95cab9b5c44c7",1,"On Neural Architecture Inductive Biases for Relational Tasks","It is found that simple architectural choices can outperform existing models in out-of-distribution generalization and show that partitioning relational representations from other information streams may be a simple way to augment existing network architectures' robustness when performing out- of-dist distribution relational computations.","arXiv.org",2022,"Giancarlo Kerg,Sarthak Mittal,D. Rolnick,Y. Bengio,B. Richards,Guillaume Lajoie",16,50,10
"b92628d13e8d090d042232fe6ae0b8998634b893","https://www.semanticscholar.org/paper/b92628d13e8d090d042232fe6ae0b8998634b893",1,"LIFT: Language-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks","Language-Interfaced Fine-Tuning is proposed and found that LIFT performs comparably well across a wide range of low-dimensional classification and regression tasks, matching the performances of the best baselines in many cases, especially for the classification tasks.","Neural Information Processing Systems",2022,"Tuan Dinh,Yuchen Zeng,Ruisu Zhang,Ziqian Lin,Shashank Rajput,Michael Gira,Jy-yong Sohn,Dimitris Papailiopoulos,Kangwook Lee",47,181,7
"40f73969cd3415e9c1b03796cbb5a50c79ebd448","https://www.semanticscholar.org/paper/40f73969cd3415e9c1b03796cbb5a50c79ebd448",1,"SALSA: Attacking Lattice Cryptography with Transformers","SALSA can fully recover secrets for small-to-mid size LWE instances with sparse binary secrets, and may scale to attack real-world LWE-based cryptosystems.","IACR Cryptology ePrint Archive",2022,"Emily Wenger,Mingjie Chen,Franccois Charton,K. Lauter",20,72,2
"4f451ba06c4c9effd6c4ac0bae222495501a6200","https://www.semanticscholar.org/paper/4f451ba06c4c9effd6c4ac0bae222495501a6200",1,"Innovations in Neural Data-to-text Generation","This survey draws boundaries separating DTG from the rest of the natural language generation (NLG) landscape, encompassing an up-to-date synthesis of the literature, and highlighting the stages of technological adoption from within and outside the greater NLG umbrella.","arXiv.org",2022,"Mandar Sharma,Ajay K. Gogineni,Naren Ramakrishnan",7,370,0
"2a7ae3e98357569c41424dacd60c62d3df78a0db","https://www.semanticscholar.org/paper/2a7ae3e98357569c41424dacd60c62d3df78a0db",1,"Limitations of Language Models in Arithmetic and Symbolic Induction","Surprisingly, large pretrained Language Models have limitations on certain basic symbolic manipulation tasks such as copy, reverse, and addition, when the total number of symbols or repeating symbols increases, the model performance drops quickly.","Annual Meeting of the Association for Computational Linguistics",2022,"Jingu Qian,Hong Wang,Zekun Li,SHIYANG LI,Xifeng Yan",36,23,2
"108c25905be36b2a7a0fc7256ac314985ecd9699","https://www.semanticscholar.org/paper/108c25905be36b2a7a0fc7256ac314985ecd9699",1,"Induced Natural Language Rationales and Interleaved Markup Tokens Enable Extrapolation in Large Language Models","This work demonstrates that large language models can succeed in extrapolation without modifying their architecture or training procedure, and shows how generating step-by-step rationales and introducing marker tokens are both required for effective extrapolation.","MATHNLP",2022,"M. Bueno,Carlos Gemmel,Jeffrey Stephen Dalton,R. Lotufo,Rodrigo Nogueira",10,66,0
"e82e3f4347674b75c432cb80604d38ee630d4bf6","https://www.semanticscholar.org/paper/e82e3f4347674b75c432cb80604d38ee630d4bf6",1,"Transformers Learn Shortcuts to Automata","It is found that a low-depth Transformer can represent the computations of any finite-state automaton (thus, any bounded-memory algorithm), by hierarchically reparameterizing its recurrent dynamics.","International Conference on Learning Representations",2022,"Bingbin Liu,J. Ash,Surbhi Goel,A. Krishnamurthy,Cyril Zhang",65,107,5
"49e46e615747f258517248de5a736814fada17ee","https://www.semanticscholar.org/paper/49e46e615747f258517248de5a736814fada17ee",1,"What is my math transformer doing? - Three results on interpretability and generalization","This paper investigates the failure cases and out-of-distribution behavior of transformers trained on matrix inversion and eigenvalue decomposition and demonstrates that, when in doubt, math transformers do not hallucinate absurd solutions but remain “roughly right”.","arXiv.org",2022,"Franccois Charton",9,14,0
"1f036b092a74f0c2f7eef37daa16eeb0f5954d9b","https://www.semanticscholar.org/paper/1f036b092a74f0c2f7eef37daa16eeb0f5954d9b",1,"Development of a Neural Network-Based Mathematical Operation Protocol for Embedded Hexadecimal Digits Using Neural Architecture Search (NAS)","A comparison between human-developed machine learning model and models sampled through Neural Architecture Search (NAS) determine an efficient approach to solve the problem of addition using embedded hexadecimal digits.","arXiv.org",2022,"Victor Robila,Kexin Pei,Junfeng Yang",0,20,0
"1a174b63d294f96568517b91f2c8d6c9362118b5","https://www.semanticscholar.org/paper/1a174b63d294f96568517b91f2c8d6c9362118b5",1,"Towards Robust Numerical Question Answering: Diagnosing Numerical Capabilities of NLP Systems","This paper proposes to conduct numerical capability diagnosis on a series of Numerical Question Answering systems and datasets and investigates the effectiveness of applying perturbations as data augmentation to relieve systems’ lack of robust numerical capabilities.","Conference on Empirical Methods in Natural Language Processing",2022,"Jialiang Xu,Mengyu Zhou,Xinyi He,Shi Han,Dongmei Zhang",3,49,1
"965e409a3e7b5670d609837fac9823b160d6639c","https://www.semanticscholar.org/paper/965e409a3e7b5670d609837fac9823b160d6639c",1,"Logical Tasks for Measuring Extrapolation and Rule Comprehension","This work defines and characterize logical tasks and discusses system requirements for their solution, and discusses the relevance of logical tasks to concepts such as extrapolation, explainability, and inductive bias.","arXiv.org",2022,"Ippei Fujisawa,R. Kanai",4,62,0
"4d17732d90440682b0500f4e209c6cc4fac20e0e","https://www.semanticscholar.org/paper/4d17732d90440682b0500f4e209c6cc4fac20e0e",1,"Teaching Algorithmic Reasoning via In-context Learning","This work shows that it is possible to teach algorithmic reasoning to LLMs via in-context learning, which it is referred to as algorithmic prompting, and evaluates the approach on a variety of arithmetic and quantitative reasoning tasks, and demonstrates significant boosts in performance.","arXiv.org",2022,"Hattie Zhou,Azade Nova,H. Larochelle,Aaron C. Courville,Behnam Neyshabur,Hanie Sedghi",69,68,10
"6c1e1cc1e0e1f8fd026fe517607b2d4535565fa7","https://www.semanticscholar.org/paper/6c1e1cc1e0e1f8fd026fe517607b2d4535565fa7",1,"PAL: Program-aided Language Models","This paper presents Program-Aided Language models (PAL): a novel approach that uses the LLM to read natural language problems and generate programs as the intermediate reasoning steps, but offloads the solution step to a runtime such as a Python interpreter.","International Conference on Machine Learning",2022,"Luyu Gao,Aman Madaan,Shuyan Zhou,Uri Alon,Pengfei Liu,Yiming Yang,Jamie Callan,Graham Neubig",233,67,45
"6845bea94b2fb17d4377b3bb2bd10f73a959f9cc","https://www.semanticscholar.org/paper/6845bea94b2fb17d4377b3bb2bd10f73a959f9cc",1,"Reasoning with Language Model Prompting: A Survey","This paper provides a comprehensive survey of cutting-edge research on reasoning with language model prompting with comparisons and summaries and provides systematic resources to help beginners.","Annual Meeting of the Association for Computational Linguistics",2022,"Shuofei Qiao,Yixin Ou,Ningyu Zhang,Xiang Chen,Yunzhi Yao,Shumin Deng,Chuanqi Tan,Fei Huang,Huajun Chen",126,219,2
"cd854d3d7a1231b1dfbbfa09a697ac064026be51","https://www.semanticscholar.org/paper/cd854d3d7a1231b1dfbbfa09a697ac064026be51",1,"Can neural networks do arithmetic? A survey on the elementary numerical skills of state-of-the-art deep learning models","This survey critically examines the recent literature, concluding that even state-of-the-art architectures and large language models often fall short when probed with relatively simple tasks designed to test basic numerical and arithmetic knowledge.","Applied Sciences",2023,"Alberto Testolin",8,120,0
"aec826ff336ca442697d5f908ab1668f1ea18987","https://www.semanticscholar.org/paper/aec826ff336ca442697d5f908ab1668f1ea18987",1,"How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model","The basic mathematical abilities often acquired by pre-trained language models are investigated, and mechanistic interpretability techniques are used to explain the (limited) mathematical abilities of GPT-2 small.","Neural Information Processing Systems",2023,"Michael Hanna,Ollie Liu,Alexandre Variengien",30,53,3
"0c43537c9b9c7b99c2ad250c9d3f82e64c82ad62","https://www.semanticscholar.org/paper/0c43537c9b9c7b99c2ad250c9d3f82e64c82ad62",1,"MultiTabQA: Generating Tabular Answers for Multi-Table Question Answering","This model, MultiTabQA, not only answers questions over multiple tables, but also generalizes to generate tabular answers, which outperforms state-of-the-art single table QA models adapted to a multi-table QA setting by finetuning on three datasets: Spider, Atis and GeoQuery.","Annual Meeting of the Association for Computational Linguistics",2023,"Vaishali Pal,Andrew Yates,E. Kanoulas,M. de Rijke",0,40,0
"d40dbe668d5b68419e934dfa4c5851ffa1c24aa2","https://www.semanticscholar.org/paper/d40dbe668d5b68419e934dfa4c5851ffa1c24aa2",1,"Exposing Attention Glitches with Flip-Flop Language Modeling","This work identifies and analyzes the phenomenon of attention glitches, in which the Transformer architecture's inductive biases intermittently fail to capture robust reasoning, and hypothesizes that attention glitches account for some of the closed-domain hallucinations in natural LLMs.","Neural Information Processing Systems",2023,"Bingbin Liu,J. Ash,Surbhi Goel,A. Krishnamurthy,Cyril Zhang",12,107,1
"3e7a0dc5795dc108c78993bcf3624fc626a9f9cf","https://www.semanticscholar.org/paper/3e7a0dc5795dc108c78993bcf3624fc626a9f9cf",1,"Opening the Black Box: Analyzing Attention Weights and Hidden States in Pre-trained Language Models for Non-language Tasks","A pre-trained language model is applied to constrained arithmetic problems with hierarchical structure, to analyze their attention weight scores and hidden states and reveals promising results, with the model addressing hierarchical problems in a moderately structured manner, similar to human problem-solving strategies.","xAI",2023,"Mohamad Ballout,U. Krumnack,G. Heidemann,Kai-Uwe Kühnberger",1,28,0
"b43383f10634f7e610f22badd4f42c93e5dcb947","https://www.semanticscholar.org/paper/b43383f10634f7e610f22badd4f42c93e5dcb947",1,"Investigating Pre-trained Language Models on Cross-Domain Datasets, a Step Closer to General AI","The ability of pre-trained language models to generalize to different non-language tasks such as computer vision, reasoning on hierarchical data, and protein fold prediction is investigated and it is found that using pre- trained embeddings for the input layer is necessary to achieve the desired results.","INNS DLIA@IJCNN",2023,"Mohamad Ballout,U. Krumnack,G. Heidemann,Kai-Uwe Kühnberger",1,28,0
"fc1ffc7df07cc9b665deca4a94b871732e1f0b4d","https://www.semanticscholar.org/paper/fc1ffc7df07cc9b665deca4a94b871732e1f0b4d",1,"Length Generalization in Arithmetic Transformers","It is shown that priming allows models trained on $5-digit $\times$ $3-digit multiplications to generalize to $35\times 3$ examples, and that the priming sample size scales as the logarithm of the training set size.","arXiv.org",2023,"Samy Jelassi,Stéphane d'Ascoli,Carles Domingo-Enrich,Yuhuai Wu,Yuan-Fang Li,Franccois Charton",15,55,3
"49d340b7d6108ce5ef2277a165ea83f254671763","https://www.semanticscholar.org/paper/49d340b7d6108ce5ef2277a165ea83f254671763",1,"The use of weather nowcasting convolutional neural network extrapolators in cardiac PET imaging",,"Journal of Medical Radiation Sciences",2023,"S. Sloka",0,25,0
"be3a74f9f6010889d049060eab2a4b09eb48bbfb","https://www.semanticscholar.org/paper/be3a74f9f6010889d049060eab2a4b09eb48bbfb",1,"The Value of Numbers in Clinical Text Classification","The results showed that even a handful of numerical features can significantly improve text classification performance, and it was concluded that commonly used document representations do not represent numbers in a way that machine learning algorithms can effectively utilize them as features.","Machine Learning and Knowledge Extraction",2023,"Kristian Miok,P. Corcoran,Irena Spasic",1,54,0
"0db0af0cd3ceb0531a050a03e6ceb849580ff53b","https://www.semanticscholar.org/paper/0db0af0cd3ceb0531a050a03e6ceb849580ff53b",1,"Teaching Arithmetic to Small Transformers","This study investigates how small transformers, trained from random initialization, can efficiently learn arithmetic operations such as addition, multiplication, and elementary functions like square root, using the next-token prediction objective.","arXiv.org",2023,"Nayoung Lee,Kartik K. Sreenivasan,Jason D. Lee,Kangwook Lee,Dimitris Papailiopoulos",24,68,5
"8f1b0c247171510fc68da27a16a377456376a5a7","https://www.semanticscholar.org/paper/8f1b0c247171510fc68da27a16a377456376a5a7",1,"Assessing GPT-3.5 and GPT-4 in Generating International Classification of Diseases Billing Codes","While the models appear to exhibit a general conceptual understanding of the codes and their descriptions, they have a propensity for hallucinating key details, suggesting underlying technological limitations of the base LLMs.","medRxiv",2023,"A. Soroush,B. Glicksberg,E. Zimlichman,Y. Barash,R. Freeman,A. Charney,G. Nadkarni,E. Klang",0,34,0
"72a9187b489992cad3d54420611d5039eb6b9d86","https://www.semanticscholar.org/paper/72a9187b489992cad3d54420611d5039eb6b9d86",1,"One Blade for One Purpose: Advancing Math Information Retrieval using Hybrid Search","This work proposes MABOWDOR, a Math-Aware Bestof-Worlds Domain Optimized Retriever, which has an unsupervised structure search component, a dense retriever, and optionally a sparse retriever on top of a domain-adapted backbone learned by context-enhanced pretraining, each addressing a different need in retrieving heterogeneous data from math documents.","Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",2023,"Wei Zhong,Sheng-Chieh Lin,Jheng-Hong Yang,Jimmy J. Lin",3,86,0
"edea0781ef29b06dc5d8aa7e9ddab3cffe87b80a","https://www.semanticscholar.org/paper/edea0781ef29b06dc5d8aa7e9ddab3cffe87b80a",1,"It Ain't That Bad: Understanding the Mysterious Performance Drop in OOD Generalization for Generative Transformer Models","It is discovered that the strong ID generalization stems from structured representations, while behind the unsatisfying OOD performance, the models still exhibit clear learned algebraic structures.","arXiv.org",2023,"Xingcheng Xu,Zihao Pan,Haipeng Zhang,Yanqing Yang",0,30,0
"cfe6d6796e37ff6ff40d3ca30e59c3df4cd47ad6","https://www.semanticscholar.org/paper/cfe6d6796e37ff6ff40d3ca30e59c3df4cd47ad6",1,"Can transformers learn the greatest common divisor?",,"arXiv.org",2023,"Franccois Charton",4,37,0
"0b778079946764292de3771a489d5ce9e1868a8b","https://www.semanticscholar.org/paper/0b778079946764292de3771a489d5ce9e1868a8b",1,"The first step is the hardest: Pitfalls of Representing and Tokenizing Temporal Data for Large Language Models","Recent works that employ LLMs for human-centric tasks are discussed and a case study showing that popular LLMs tokenize temporal data incorrectly is presented, highlighting potential solutions that can help bridge this ""modality gap"".","arXiv.org",2023,"Dimitris Spathis,F. Kawsar",4,40,0
"174a9b78350e9561555052bc6901cc44782f4c62","https://www.semanticscholar.org/paper/174a9b78350e9561555052bc6901cc44782f4c62",1,"Estimating Numbers without Regression","A carefully designed tokenization scheme is both the simplest to implement and sufficient, with similar performance to the state-of-the-art approach that requires making significant architectural changes, in the context of masked number prediction.","arXiv.org",2023,"Avijit Thawani,Jay Pujara,Ashwin Kalyan",1,17,0
"200fcd964f41efe0c35a3f888a520ede08a3269c","https://www.semanticscholar.org/paper/200fcd964f41efe0c35a3f888a520ede08a3269c",1,"From Interpolation to Extrapolation: Complete Length Generalization for Arithmetic Transformers","It is shown that transformer models are able to generalize to long lengths with the help of targeted attention biasing, and it is demonstrated that using ABC, the transformer model can achieve unprecedented near-perfect length generalization on certain arithmetic tasks.","arXiv.org",2023,"Shaoxiong Duan,Yining Shi",1,30,0
"1ec3a3ff77cb4b424499b3805ecc90182ecd8f8b","https://www.semanticscholar.org/paper/1ec3a3ff77cb4b424499b3805ecc90182ecd8f8b",1,"What Algorithms can Transformers Learn? A Study in Length Generalization","This work proposes a unifying framework to understand when and how Transformers can exhibit strong length generalization on a given task and provides a novel perspective on the mechanisms of compositional generalization and the algorithmic capabilities of Transformers.","arXiv.org",2023,"Hattie Zhou,Arwen Bradley,Etai Littwin,Noam Razin,O. Saremi,Josh Susskind,Samy Bengio,Preetum Nakkiran",16,55,2
"4726d1dc54851db99c29180127d840bd19f20afc","https://www.semanticscholar.org/paper/4726d1dc54851db99c29180127d840bd19f20afc",1,"Positional Description Matters for Transformers Arithmetic","This work delve deeper into the role of positional encoding, and proposes several ways to fix the issue, either by modifying the positional encoding directly, or by modified the representation of the arithmetic task to leverage standard positional encoding differently.","arXiv.org",2023,"Ruoqi Shen,Sébastien Bubeck,Ronen Eldan,Yin Tat Lee,Yuanzhi Li,Yi Zhang",4,25,1
"2aeaad5548229dec7fdf716f7e83a5a359665852","https://www.semanticscholar.org/paper/2aeaad5548229dec7fdf716f7e83a5a359665852",1,"Carrying over algorithm in transformers","A simple way of precisely identifying which neurons are responsible for that task in the carrying over algorithm is provided, across a range of hyperparameters for two as well as three-layer models.","arXiv.org",2024,"J. Kruthoff",1,37,0
"a640215755e23e2649f4b3d3246a47b14fea93f7","https://www.semanticscholar.org/paper/a640215755e23e2649f4b3d3246a47b14fea93f7",1,"Getting the most out of your tokenizer for pre-training and domain adaptation","It is shown that the size, pre-tokenization regular expression, and training data of a tokenizer can significantly impact the model's generation speed, effective context size, memory usage, and downstream performance.","arXiv.org",2024,"Gautier Dagan,Gabriele Synnaeve,Baptiste Roziere",0,45,0
"d9e76ae6480114d81da2e9eb98f848df120be057","https://www.semanticscholar.org/paper/d9e76ae6480114d81da2e9eb98f848df120be057",1,"Salsa Fresca: Angular Embeddings and Pre-Training for ML Attacks on Learning With Errors","This work is the first instance of ML attacks recovering sparse binary secrets in dimension $n=1024$, the smallest dimension used in practice for homomorphic encryption applications of LWE where sparse binary secrets are proposed.","IACR Cryptology ePrint Archive",2024,"Samuel Stevens,Emily Wenger,C. Li,Niklas Nolte,Eshika Saxena,François Charton,Kristin E. Lauter",0,58,0
"bc4e1552d3c12180fd13d59e155861a6eb2fbdab","https://www.semanticscholar.org/paper/bc4e1552d3c12180fd13d59e155861a6eb2fbdab",1,"Lissard: Long and Simple Sequential Reasoning Datasets","This paper introduces Lissard, a benchmark comprising seven tasks whose goal is to assess the ability of models to process and generate wide-range sequence lengths, requiring repetitive procedural execution.","arXiv.org",2024,"M. Bueno,R. Lotufo,Rodrigo Nogueira",0,25,0
"61547f92cbba68629f470ece8019c4140c506706","https://www.semanticscholar.org/paper/61547f92cbba68629f470ece8019c4140c506706",1,"Show Me How It's Done: The Role of Explanations in Fine-Tuning Language Models","It is argued that despite the challenging nature of adding explanations, samples that contain explanations not only reduce the volume of data required for training but also promote a more effective generalization by the model.","arXiv.org",2024,"Mohamad Ballout,U. Krumnack,Gunther Heidemann,Kai-Uwe Kuehnberger",0,32,0
"6f63ad08cf27183ceb2976b9fb6599ed9b31a522","https://www.semanticscholar.org/paper/6f63ad08cf27183ceb2976b9fb6599ed9b31a522",1,"OmniPred: Language Models as Universal Regressors","OmniPred is proposed, a framework for training language models as universal end-to-end regressors over $(x,y)$ evaluation data from diverse real world experiments that demonstrate that through only textual representations of mathematical parameters and values, language models are capable of very precise numerical regression, and if given the opportunity to train over multiple tasks, can significantly outperform traditional regression models.","",2024,"Xingyou Song,Oscar Li,Chansoo Lee,Bangding Yang,Daiyi Peng,Sagi Perel,Yutian Chen",0,44,0
"f740a2474b52675287166a003bd1313f8aabcd68","https://www.semanticscholar.org/paper/f740a2474b52675287166a003bd1313f8aabcd68",1,"BioT5+: Towards Generalized Biological Understanding with IUPAC Integration and Multi-task Tuning","This paper introduces BioT5+, an extension of the BioT5 framework, tailored to enhance biological research and drug discovery, and incorporates several novel features that allow BioT5+ to bridge the gap between molecular representations and their textual descriptions, providing a more holistic understanding of biological entities.","",2024,"Qizhi Pei,Lijun Wu,Kaiyuan Gao,Xiaozhuan Liang,Yin Fang,Jinhua Zhu,Shufang Xie,Tao Qin,Rui Yan",2,85,0
"17ba73a2a332a44bb1a00622beab96f33d4b1ba7","https://www.semanticscholar.org/paper/17ba73a2a332a44bb1a00622beab96f33d4b1ba7",1,"RORA: Robust Free-Text Rationale Evaluation","RORA consistently outperforms existing approaches in evaluating human-written, synthetic, or model-generated rationales, particularly demonstrating robustness against label leakage and aligns well with human judgment, providing a more reliable and accurate measurement across diverse free-text rationales.","",2024,"Zhengping Jiang,Yining Lu,Hanjie Chen,Daniel Khashabi,B. V. Durme,Anqi Liu",0,73,0
"36f46391b00a7eb4ffc991f964a36b264811057d","https://www.semanticscholar.org/paper/36f46391b00a7eb4ffc991f964a36b264811057d",1,"Mathify: Evaluating Large Language Models on Mathematical Problem Solving Tasks","An extensive mathematics dataset called "" MathQuest "" sourced from the 11th and 12th standard Mathematics NCERT textbooks is introduced, and MAmmoTH-13B establishes itself as a robust and dependable benchmark for addressing NCERT mathematics problems.","",,"Avinash Anand,Mohit Gupta,Kritarth Prasad,Navya Singla,Sanjana Sanjeev,Jatin Kumar,A. Shivam,Rajiv Ratn",1,28,0
"651dac86d8bf847ec6780a878cb1e04d3d41f356","https://www.semanticscholar.org/paper/651dac86d8bf847ec6780a878cb1e04d3d41f356",1,"GPT as Knowledge Worker: A Zero-Shot Evaluation of (AI)CPA Capabilities",,"Social Science Research Network",2023,"Jillian Bommarito,M. Bommarito,D. Katz,Jessica Katz",37,36,2
"763f47b73d0273a93a52a8ee8a63cf19009df6e1","https://www.semanticscholar.org/paper/763f47b73d0273a93a52a8ee8a63cf19009df6e1",1,"Injecting the BM25 Score as Text Improves BERT-Based Re-rankers","The findings indicate that cross-encoder re-rankers can efficiently be improved without additional computational burden and extra steps in the pipeline by explicitly adding the output of the first-stage ranker to the model input, and this effect is robust for different models and query types.","European Conference on Information Retrieval",2023,"Arian Askari,Amin Abolghasemi,G. Pasi,Wessel Kraaij,S. Verberne",13,73,1
"f0ea9e2d3889d37f34743ed1dc64f11e8e0484de","https://www.semanticscholar.org/paper/f0ea9e2d3889d37f34743ed1dc64f11e8e0484de",1,"Numeracy from Literacy: Data Science as an Emergent Skill from Large Language Models","The work examines whether next-token prediction succeeds from sentence completion into the realm of actual numerical understanding and showcases the model's capabilities to group by or pivot categorical sums, infer feature importance, derive correlations, and predict unseen test cases using linear regression.","arXiv.org",2023,"David A. Noever,Forrest McKee",8,44,0
"ade6d2808283ab8372db701ede6ee145a5445a95","https://www.semanticscholar.org/paper/ade6d2808283ab8372db701ede6ee145a5445a95",1,"SLaDe: A Portable Small Language Model Decompiler for Optimized Assembly","SLaDe, a Small Language model Decompiler based on a sequence-to-sequence Transformer trained over real-world code and augmented with a type inference engine is presented, utilizing a novel tokenizer, dropout-free regularization, and type inference to generate programs that are more readable and accurate than standard analytic and recent neural approaches.","IEEE/ACM International Symposium on Code Generation and Optimization",2023,"Jordi Armengol-Estap'e,Jackson Woodruff,Chris Cummins,M. O’Boyle",5,68,0
"24a285b1e7ee9acfec9a82f7123563b62f532203","https://www.semanticscholar.org/paper/24a285b1e7ee9acfec9a82f7123563b62f532203",1,"FERMAT: An Alternative to Accuracy for Numerical Reasoning","This work introduces a multi-view evaluation set for numerical reasoning in English, called FERMAT, which evaluates models on various key numerical reasoning aspects such as number understanding, mathematical operations, and training dependency.","Annual Meeting of the Association for Computational Linguistics",2023,"Jasivan Sivakumar,N. Moosavi",1,48,0
"7ef0cc95ff71c1098414cd61e88ac373ea2db4c4","https://www.semanticscholar.org/paper/7ef0cc95ff71c1098414cd61e88ac373ea2db4c4",1,"Performance of Generative Large Language Models on Ophthalmology Board Style Questions.","The frequency of hallucinations and non-logical reasoning suggest room for improvement in the performance of conversational agents in the medical domain.","American journal of ophthalmology-glaucoma",2023,"Louis Z Cai,Abdulla R. Shaheen,Andrew C. Jin,Riya Fukui,Jonathan S. Yi,Nicolas A. Yannuzzi,C. Alabiad",18,8,1
"a37d5620210276e47cf0c9dd2898c2a82c9d0422","https://www.semanticscholar.org/paper/a37d5620210276e47cf0c9dd2898c2a82c9d0422",1,"Simple synthetic data reduces sycophancy in large language models","A straightforward synthetic-data intervention is presented that takes public NLP tasks and encourages models to be robust to user opinions on these tasks and can significantly reduce sycophantic behavior on held-out prompts.","arXiv.org",2023,"Jerry W. Wei,Da Huang,Yifeng Lu,Denny Zhou,Quoc V. Le",18,62,1
"5be5619fc22300ef356ec4ef729d567ce7116c57","https://www.semanticscholar.org/paper/5be5619fc22300ef356ec4ef729d567ce7116c57",1,"Exploring the Numerical Reasoning Capabilities of Language Models: A Comprehensive Analysis on Tabular Data","A hierarchical taxonomy for numerical reasoning skills with more than ten reasoning types across four levels: representation, number sense, manipulation, and complex reasoning is proposed.","Conference on Empirical Methods in Natural Language Processing",2023,"Mubashara Akhtar,Abhilash Shankarampeta,Vivek Gupta,Arpit Patil,O. Cocarascu,Elena Simperl",1,62,0